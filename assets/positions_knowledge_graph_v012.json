{"nodes": [{"data": {"id": "Machine_Learning", "name": "Machine Learning", "colour": "#ff00ff", "nodetype": "field"}, "classes": "subject", "position": {"x": 3257.69148492605, "y": 1125.6573316064223}}, {"data": {"id": "Optimization", "name": "Optimization", "colour": "#ff7eff", "nodetype": "field"}, "classes": "subject", "position": {"x": 4533.916689381322, "y": 1298.7799023050613}}, {"data": {"id": "Deep_Learning", "name": "Deep Learning", "colour": "#d4ddff", "nodetype": "field"}, "classes": "subject", "position": {"x": 3931.048134239869, "y": 21.12880357787941}}, {"data": {"id": "Calculus", "name": "Calculus", "colour": "#7effff", "nodetype": "field"}, "classes": "subject", "position": {"x": 4373.791146837981, "y": 3056.290906760813}}, {"data": {"id": "Probability_&_Statistics", "name": "Probability & Statistics", "colour": "#2addff", "nodetype": "field"}, "classes": "subject", "position": {"x": 2924.4102177589257, "y": 2830.274110088283}}, {"data": {"id": "Linear_Algebra", "name": "Linear Algebra", "colour": "#2c7eff", "nodetype": "field"}, "classes": "subject", "position": {"x": 1113.0431053413083, "y": 2536.3321822611074}}, {"data": {"id": "Reinforcement_Learning", "name": "Reinforcement Learning", "colour": "#8000ff", "nodetype": "field"}, "classes": "subject", "position": {"x": 1801.943581837018, "y": 802.5781889931158}}, {"data": {"id": "1", "name": "What is a Matrix? (& Transposes)", "lectures": "Linear Algebra course 1-13", "description": "A matrix is essentially a container of scalar numbers.", "urls": ["https://www.khanacademy.org/math/preCalculus/x9e81a4f98389efdf:matrices/x9e81a4f98389efdf:mat-intro/v/introduction-to-the-matrix", "https://www.khanacademy.org/math/algebra-home/alg-matrices/alg-adding-and-subtracting-matrices/v/matrix-addition-and-subtraction-1", "https://www.khanacademy.org/math/algebra-home/alg-matrices/alg-multiplying-matrices-by-scalars/v/scalar-multiplication", ""], "nodetype": "concept", "relative_importance": 1.5652475842498528, "parent": "Linear_Algebra"}, "classes": "concept", "position": {"x": 1325.1317512274327, "y": 3455.5347668639142}}, {"data": {"id": "2", "name": "Matrix Multiplication", "lectures": "Linear Algebra course 1-13", "description": "Calculate the product of two matrices", "urls": ["https://www.khanacademy.org/math/algebra-home/alg-matrices/alg-multiplying-matrices-by-matrices/v/matrix-multiplication-intro", "https://www.khanacademy.org/math/algebra-home/alg-matrices/alg-properties-of-matrix-multiplication/v/defined-and-undefined-matrix-operations", "https://www.youtube.com/watch?v=XkY2DOUCWMU&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&index=4"], "nodetype": "concept", "relative_importance": 1.5652475842498528, "parent": "Linear_Algebra"}, "classes": "concept", "position": {"x": 1333.144242793755, "y": 3018.6668368580713}}, {"data": {"id": "3", "name": "Inversion & Singular Matrices", "lectures": "", "description": "Inversion is the process of find the matrix that multiplies a matrix to produce the identity matrix. Singular matrices are non-invertible.", "urls": ["https://www.khanacademy.org/math/algebra-home/alg-matrices/alg-intro-to-matrix-inverses/v/inverse-matrix-part-1", "https://www.khanacademy.org/math/algebra-home/alg-matrices/alg-finding-inverse-matrix-with-determinant/v/inverse-of-a-2x2-matrix"], "nodetype": "concept", "relative_importance": 1.4, "parent": "Linear_Algebra"}, "classes": "concept", "position": {"x": 782.5543074362811, "y": 2555.1997383793937}}, {"data": {"id": "4", "name": "Linear Equations (Ax=b)", "lectures": "Linear Algebra course 1-13", "description": "Using linear algebra to solve linear equations", "urls": ["https://www.khanacademy.org/math/algebra-home/alg-matrices/alg-solving-equations-with-inverse-matrices/v/matrix-equations-systems", "https://www.coursera.org/lecture/linear-algebra-machine-learning/matrices-vectors-and-solving-simultaneous-equation-problems-jGab3"], "nodetype": "concept", "relative_importance": 1.212435565298214, "parent": "Linear_Algebra"}, "classes": "concept", "position": {"x": 1373.7429797635536, "y": 2191.5084013179608}}, {"data": {"id": "5", "name": "Vector Spaces & Basis", "lectures": "Linear Algebra course 1-13", "description": "A vector space is a set of vectors in which any scalar multiplication can occur and the result remains in the space", "urls": ["https://www.khanacademy.org/math/linear-algebra/vectors-and-spaces/subspace-basis/v/linear-subspaces", "https://www.khanacademy.org/math/linear-algebra/vectors-and-spaces/subspace-basis/v/linear-algebra-basis-of-a-subspace"], "nodetype": "concept", "relative_importance": 1.4, "parent": "Linear_Algebra"}, "classes": "concept", "position": {"x": 784.4848162446381, "y": 2342.654179895814}}, {"data": {"id": "6", "name": "Rank", "lectures": "", "description": "", "urls": ["https://www.khanacademy.org/math/linear-algebra/vectors-and-spaces/null-column-space/v/dimension-of-the-column-space-or-rank"], "nodetype": "concept", "relative_importance": 1, "parent": "Linear_Algebra"}, "classes": "concept", "position": {"x": 1283.8360130670826, "y": 2745.4583274500364}}, {"data": {"id": "7", "name": "Permutations", "lectures": "Linear Algebra course 1-13", "description": "", "urls": ["https://www.youtube.com/watch?v=d7AovBKeNMI", "https://www.youtube.com/watch?v=8OSAsm5tTwU", "https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/video-lectures/lecture-5-transposes-permutations-spaces-r-n"], "nodetype": "concept", "relative_importance": 1, "parent": "Linear_Algebra"}, "classes": "concept", "position": {"x": 360.10601432062685, "y": 1763.8427309003632}}, {"data": {"id": "9", "name": "Random Variables", "lectures": "probability course 1-12", "description": "Variables whose possible values are numerical outcomes of a random phenomenon", "urls": ["https://www.khanacademy.org/math/statistics-probability/random-variables-stats-library", "https://www.youtube.com/watch?v=vfqPpai_9jI"], "nodetype": "concept", "relative_importance": 1, "parent": "Probability_&_Statistics"}, "classes": "concept", "position": {"x": 2805.050404866635, "y": 4045.366160602146}}, {"data": {"id": "10", "name": "Probability Axioms", "lectures": "probability course 1-12", "description": "The fundamental rules of probability theory", "urls": ["https://www.youtube.com/watch?v=UjcGyISekpE", "https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-i-the-fundamentals"], "nodetype": "concept", "relative_importance": 1, "parent": "Probability_&_Statistics"}, "classes": "concept", "position": {"x": 2807.7715664118355, "y": 3704.432985817325}}, {"data": {"id": "11", "name": "Probability density/mass functions", "lectures": "probability course 1-12", "description": "", "urls": ["https://www.khanacademy.org/math/statistics-probability/random-variables-stats-library/random-variables-continuous/v/probability-density-functions", "https://www.khanacademy.org/math/statistics-probability/random-variables-stats-library/random-variables-continuous/v/probabilities-from-density-curves", "https://www.youtube.com/watch?v=iThbNOsDj0Q", "https://www.youtube.com/watch?v=YXLVjCKVP7U"], "nodetype": "concept", "relative_importance": 1.9798989873223332, "parent": "Probability_&_Statistics"}, "classes": "concept", "position": {"x": 2814.8538255695485, "y": 3546.509110543897}}, {"data": {"id": "12", "name": "Cumulative Distribution Functions", "lectures": "", "description": "", "urls": ["https://www.youtube.com/watch?v=YXLVjCKVP7U", "https://www.youtube.com/watch?v=ZJsOOCghQJ0"], "nodetype": "concept", "relative_importance": 1, "parent": "Probability_&_Statistics"}, "classes": "concept", "position": {"x": 3165.4925939181694, "y": 3069.6592297990824}}, {"data": {"id": "13", "name": "Expectations", "lectures": "", "description": "What you would expect the value of random variables to be on average", "urls": ["https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-i-the-fundamentals", "https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-i-the-fundamentals", "https://www.khanacademy.org/math/statistics-probability/random-variables-stats-library/random-variables-discrete/v/expected-value-of-a-discrete-random-variable"], "nodetype": "concept", "relative_importance": 1, "parent": "Probability_&_Statistics"}, "classes": "concept", "position": {"x": 3744.4193474389544, "y": 2853.752768255145}}, {"data": {"id": "14", "name": "Conditional Probability & Independence", "lectures": "", "description": "The rules governing different random variables that are correlated or depend on one another", "urls": ["https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-i-the-fundamentals", "https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-i-the-fundamentals"], "nodetype": "concept", "relative_importance": 1, "parent": "Probability_&_Statistics"}, "classes": "concept", "position": {"x": 3265.292893756615, "y": 2802.8226813025103}}, {"data": {"id": "15", "name": "Variance", "lectures": "probability course 1-12", "description": "Variance is a measure of the spread of data from their mean value", "urls": ["https://ocw.mit.edu/resources/res-6-012-introduction-to-probability-spring-2018/part-i-the-fundamentals"], "nodetype": "concept", "relative_importance": 1.5652475842498528, "parent": "Probability_&_Statistics"}, "classes": "concept", "position": {"x": 2393.8749939322515, "y": 2853.0503870006182}}, {"data": {"id": "16", "name": "Bayes' Theorem", "lectures": "probability course 1-12", "description": "Bayes' theorem describes the probability of an event, based on prior knowledge of conditions that might be related to the event.", "urls": ["https://www.youtube.com/watch?v=HZGCoVF3YvM", "http://www.mas.ncl.ac.uk/~nlf8/teaching/mas2317/notes/chapter2.pdf", "http://pillowlab.princeton.edu/teaching/mathtools16/slides/lec13_BayesRule.pdf"], "nodetype": "concept", "relative_importance": 1.212435565298214, "parent": "Probability_&_Statistics"}, "classes": "concept", "position": {"x": 3300.46616738627, "y": 2074.5267766435786}}, {"data": {"id": "17", "name": "Differentiation", "lectures": "", "description": "Differentation is the process of finding the differential of a function, which is a function describing the sensitivity to change of it's argument", "urls": ["https://www.khanacademy.org/math/differential-Calculus/dc-diff-intro/dc-derivative-intro/v/Calculus-derivatives-1-new-hd-version?modal=1", "https://www.youtube.com/watch?v=9AI3BkKQhn0", "https://www.youtube.com/watch?v=NRSmIE5MMBQ&list=PL5KkMZvBpo5DwIsDKWdHYmkRZmXMi1mE8", "https://www.youtube.com/watch?v=lowavG2SXsQ&list=PLmdFyQYShrjd4Qn42rcBeFvF6Qs-b6e-L&index=9", "https://www.youtube.com/watch?v=AOkn9-UK5AU&list=PLmdFyQYShrjd4Qn42rcBeFvF6Qs-b6e-L&index=10", "https://www.derivative-calculator.net/"], "nodetype": "concept", "relative_importance": 1.5652475842498528, "parent": "Calculus"}, "classes": "concept", "position": {"x": 4351.443625840804, "y": 4094.4143083941817}}, {"data": {"id": "18", "name": "Product Rule", "lectures": "", "description": "A method for finding the derivatives of the products of two or more functions", "urls": ["https://www.youtube.com/watch?v=17X5g9QArTc", "https://www.youtube.com/watch?v=h78GdGiRmpM"], "nodetype": "concept", "relative_importance": 1, "parent": "Calculus"}, "classes": "concept", "position": {"x": 4760.552573070115, "y": 3254.7282276569617}}, {"data": {"id": "19", "name": "Chain Rule", "lectures": "", "description": "The chain rule provides a method of finding the derivative of composite functions. Knowing the change in z relative y and change in y relative to x lets us find the rate of change of z relative to x.", "urls": ["https://www.khanacademy.org/math/ap-Calculus-ab/ab-differentiation-2-new/ab-3-1a/v/chain-rule-introduction"], "nodetype": "concept", "relative_importance": 1, "parent": "Calculus"}, "classes": "concept", "position": {"x": 4779.384919207781, "y": 2069.4370094690394}}, {"data": {"id": "20", "name": "Integration", "lectures": "", "description": "Methods for finding the area under a curve of a function", "urls": ["https://www.khanacademy.org/math/ap-Calculus-ab/ab-integration-new/ab-6-1/v/introduction-to-integral-Calculus"], "nodetype": "concept", "relative_importance": 1.212435565298214, "parent": "Calculus"}, "classes": "concept", "position": {"x": 3979.5711304585266, "y": 3972.840603815362}}, {"data": {"id": "22", "name": "Cost functions", "lectures": "Machine Learning week 1-2", "description": "Measures of how wrong a model is in estimating the relationship between it's inputs and the desired output", "urls": ["https://www.youtube.com/watch?v=euhATa4wgzo", "https://towardsdatascience.com/machine-learning-fundamentals-via-linear-regression-41a5d11f5220"], "nodetype": "concept", "relative_importance": 1, "parent": "Optimization"}, "classes": "concept", "position": {"x": 4598.71082835608, "y": 1537.8259285750319}}, {"data": {"id": "23", "name": "Intro to Optimisation", "lectures": "", "description": "The process of maximising or minimizing a function by systematically choosing input values", "urls": ["https://www.khanacademy.org/math/ap-calculus-ab/ab-diff-analytical-applications-new/ab-5-11/v/minimizing-sum-of-squares", "http://scipy-lectures.org/advanced/mathematical_optimization/", "https://deepai.org/machine-learning-glossary-and-terms/mathematical-optimization", "https://www.youtube.com/watch?v=vwUV2IDLP8Q", "https://www.youtube.com/watch?v=Ef22yTJDUZI", "https://www.youtube.com/watch?v=HsUY94Fjxao", "https://www.youtube.com/watch?v=qiku9Up_DAA"], "nodetype": "concept", "relative_importance": 1.4, "parent": "Optimization"}, "classes": "concept", "position": {"x": 4613.459597526627, "y": 1897.9708026356736}}, {"data": {"id": "24", "name": "Projection Matrices", "lectures": "Linear Algebra course 14-24", "description": "", "urls": ["https://www.youtube.com/watch?v=Y_Ac6KiQ1t0", "https://www.khanacademy.org/math/linear-algebra/alternate-bases/orthogonal-projections/v/linear-algebra-projections-onto-subspaces"], "nodetype": "concept", "relative_importance": 1, "parent": "Linear_Algebra"}, "classes": "concept", "position": {"x": 996.9006721235792, "y": 2206.913629633707}}, {"data": {"id": "25", "name": "Ax=b Least Squares", "lectures": "", "description": "A method for estimating unknown parameters based on mimizing the squared distance between datapoints and a regression line", "urls": ["http://math.mit.edu/~gs/linearalgebra/ila0403.pdf"], "nodetype": "concept", "relative_importance": 1, "parent": "Linear_Algebra"}, "classes": "concept", "position": {"x": 1631.9929886641971, "y": 1834.4269991116464}}, {"data": {"id": "26", "name": "Linear Regression", "lectures": "Linear Algebra course 14-24,      Machine Learning week 1-2", "description": "A linear approach to esitimating the relationship between an depedent and independent variables", "urls": ["https://www.youtube.com/watch?v=ZkjP5RJLQF4", "http://www.stat.yale.edu/Courses/1997-98/101/linreg.htm"], "nodetype": "concept", "relative_importance": 1, "parent": "Probability_&_Statistics"}, "classes": "concept", "position": {"x": 2104.9180662187737, "y": 2476.9114820950717}}, {"data": {"id": "27", "name": "Orthogonal Matrices", "lectures": "Linear Algebra course 14-24", "description": "", "urls": ["https://www.youtube.com/watch?v=0MtwqhIwdrI", "https://mathworld.wolfram.com/OrthogonalMatrix.html", "https://www.youtube.com/watch?v=IGBm-gZryVI"], "nodetype": "concept", "relative_importance": 1.212435565298214, "parent": "Linear_Algebra"}, "classes": "concept", "position": {"x": 577.8716213890739, "y": 2054.4700778289734}}, {"data": {"id": "28", "name": "Determinants", "lectures": "Linear Algebra course 14-24", "description": "", "urls": ["https://www.khanacademy.org/math/algebra-home/alg-matrices/alg-determinant-of-2x2-matrix/v/finding-the-determinant-of-a-2x2-matrix", "https://www.khanacademy.org/math/algebra-home/alg-matrices/alg-determinants-and-inverses-of-large-matrices/v/finding-the-determinant-of-a-3x3-matrix-method-2", "https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/video-lectures/lecture-18-properties-of-determinants/"], "nodetype": "concept", "relative_importance": 1.212435565298214, "parent": "Linear_Algebra"}, "classes": "concept", "position": {"x": 776.2459537737924, "y": 2953.052856745461}}, {"data": {"id": "29", "name": "Cofactors", "lectures": "", "description": "", "urls": ["https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/video-lectures/lecture-19-determinant-formulas-and-cofactors/"], "nodetype": "concept", "relative_importance": 1, "parent": "Linear_Algebra"}, "classes": "concept", "position": {"x": 404.69010335199386, "y": 2612.869789350458}}, {"data": {"id": "30", "name": "Eigenvectors & Eigenvalues", "lectures": "Linear Algebra course 14-24", "description": "", "urls": ["https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/video-lectures/lecture-21-eigenvalues-and-eigenvectors/", "https://www.youtube.com/watch?v=PFDu9oVAE-g"], "nodetype": "concept", "relative_importance": 1, "parent": "Linear_Algebra"}, "classes": "concept", "position": {"x": 1249.2003447807365, "y": 1822.6995985901274}}, {"data": {"id": "31", "name": "Diagonalization", "lectures": "Linear Algebra course 14-24", "description": "", "urls": ["https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/video-lectures/lecture-22-diagonalization-and-powers-of-a/"], "nodetype": "concept", "relative_importance": 1, "parent": "Linear_Algebra"}, "classes": "concept", "position": {"x": 776.4909250484083, "y": 1880.0678911888203}}, {"data": {"id": "32", "name": "Transformed distributions", "lectures": "", "description": "", "urls": ["https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-436j-fundamentals-of-probability-fall-2018/lecture-notes/MIT6_436JF18_lec12.pdf", "https://web.mit.edu/urban_or_book/www/book/chapter3/3.1.html#:~:text=Often%20when%20examining%20a%20system", "of%20the%20original%20random%20variables."], "nodetype": "concept", "relative_importance": 1, "parent": "Probability_&_Statistics"}, "classes": "concept", "position": {"x": 3691.1929170286785, "y": 3137.0491896190724}}, {"data": {"id": "33", "name": "Convolutions", "lectures": "", "description": "", "urls": ["https://colah.github.io/posts/2014-07-Understanding-Convolutions/", "https://www.khanacademy.org/math/differential-equations/laplace-transform/convolution-integral/v/introduction-to-the-convolution", ""], "nodetype": "concept", "relative_importance": 1, "parent": "Calculus"}, "classes": "concept", "position": {"x": 3979.1973744681795, "y": 2031.851563105448}}, {"data": {"id": "34", "name": "Central Limit Theorem", "lectures": "", "description": "In populations with a mean and standard deviation, if you take a sufficient number of samples, the means of those samples will be normally distributed", "urls": ["https://www.khanacademy.org/math/ap-statistics/sampling-distribution-ap/sampling-distribution-mean/v/central-limit-theorem", "https://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_probability/BS704_Probability12.html"], "nodetype": "concept", "relative_importance": 1, "parent": "Probability_&_Statistics"}, "classes": "concept", "position": {"x": 2229.153352540167, "y": 2157.6177799697143}}, {"data": {"id": "35", "name": "Gaussian Distribution", "lectures": "probability course 1-12", "description": "A continuous probability distribution to approximate random variables. Also known as the 'normal distribution' or informally as the 'bell curve'", "urls": ["https://www.khanacademy.org/math/statistics-probability/modeling-distributions-of-data/more-on-normal-distributions/v/introduction-to-the-normal-distribution", "https://www.youtube.com/watch?v=iYiOVISWXS4"], "nodetype": "concept", "relative_importance": 1.212435565298214, "parent": "Probability_&_Statistics"}, "classes": "concept", "position": {"x": 2372.394558430766, "y": 2475.2760717972296}}, {"data": {"id": "36", "name": "Covariance", "lectures": "probability course 1-12", "description": "A measure of the strength of correlation between two or more random variables", "urls": ["https://www.khanacademy.org/math/statistics-probability/describing-relationships-quantitative-data/more-on-regression/v/covariance-and-the-regression-line", "https://www.youtube.com/watch?v=4EXNedimDMs", "https://www.khanacademy.org/math/ap-statistics/bivariate-data-ap/correlation-coefficient-r/v/calculating-correlation-coefficient-rhttps://www.itl.nist.gov/div898/handbook/pmc/section5/pmc541.htm", "https://towardsdatascience.com/let-us-understand-the-correlation-matrix-and-covariance-matrix-d42e6b643c22#:~:text=%E2%80%9CCovariance%E2%80%9D%20indicates%20the%20direction%20of", "linear%20relationship%20between%20two%20variables."], "nodetype": "concept", "relative_importance": 1, "parent": "Probability_&_Statistics"}, "classes": "concept", "position": {"x": 2704.6950627369656, "y": 2461.393528572472}}, {"data": {"id": "41", "name": "Singular value decomposition", "lectures": "Linear Algebra course 25-34", "description": "", "urls": ["https://web.mit.edu/be.400/www/SVD/Singular_Value_Decomposition.htm", "https://towardsdatascience.com/understanding-singular-value-decomposition-and-its-application-in-data-science-388a54be95d", "https://www.youtube.com/watch?v=mBcLRGuAFUk", "https://www.youtube.com/watch?v=rYz83XPxiZo"], "nodetype": "concept", "relative_importance": 1, "parent": "Linear_Algebra"}, "classes": "concept", "position": {"x": 979.5898633631641, "y": 1657.0636556363042}}, {"data": {"id": "42", "name": "Change of basis", "lectures": "Linear Algebra course 25-34", "description": "", "urls": ["https://www.youtube.com/watch?v=P2LTAUO1TdA", "https://www.youtube.com/watch?v=1j5WnqwMdCk", "https://www.youtube.com/watch?v=0h43aV4aH7I"], "nodetype": "concept", "relative_importance": 1.212435565298214, "parent": "Linear_Algebra"}, "classes": "concept", "position": {"x": 1170.640674754367, "y": 2081.2832637686843}}, {"data": {"id": "45", "name": "Maximum A Posteriori (MAP) estimation", "lectures": "probability course 19-25", "description": "", "urls": ["https://www.youtube.com/watch?v=kkhdIriddSI", "https://machinelearningmastery.com/maximum-a-posteriori-estimation/"], "nodetype": "concept", "relative_importance": 1, "parent": "Probability_&_Statistics"}, "classes": "concept", "position": {"x": 3561.5851655477213, "y": 1783.7261340066132}}, {"data": {"id": "46", "name": "Maximum Likelihood (ML) estimation", "lectures": "probability course 19-25", "description": "", "urls": ["https://www.youtube.com/watch?v=00krscK7iBA", "https://towardsdatascience.com/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1", "https://towardsdatascience.com/a-gentle-introduction-to-maximum-likelihood-estimation-9fbff27ea12f"], "nodetype": "concept", "relative_importance": 1, "parent": "Probability_&_Statistics"}, "classes": "concept", "position": {"x": 3795.555322856338, "y": 1721.1820595744202}}, {"data": {"id": "56", "name": "Generative & Discriminative Models", "lectures": "Machine Learning week 8", "description": "", "urls": ["https://www.youtube.com/watch?v=oTtow2Ui8vg", "https://medium.com/@mlengineer/generative-and-discriminative-models-af5637a66a3#:~:text=In%20General%2C%20A%20Discriminative%20model", "actual%20distribution%20of%20each%20class.&text=A%20Discriminative%20model%20%E2%80%8Clearns%20the", "used%20in%20supervised%20learning%20problems.", "https://stats.stackexchange.com/questions/12421/generative-vs-discriminative"], "nodetype": "concept", "relative_importance": 1.4, "parent": "Machine_Learning"}, "classes": "concept", "position": {"x": 3374.4056031153764, "y": 1492.441351937193}}, {"data": {"id": "57", "name": "Entropy", "lectures": "Machine Learning week 4,8", "description": "The measure of uncertainty associated with the values taken by a random variable. Can also be described as the quantity of information in a set of random variables", "urls": ["http://colah.github.io/posts/2015-09-Visual-Information/#codes", "https://www.youtube.com/watch?v=YM-uykVfq_E", "https://www.youtube.com/watch?v=8N1BxHgsoOw"], "nodetype": "concept", "relative_importance": 1, "parent": "Probability_&_Statistics"}, "classes": "concept", "position": {"x": 3011.450963633057, "y": 2327.23697289125}}, {"data": {"id": "58", "name": "KL Divergence", "lectures": "", "description": "", "urls": ["https://www.youtube.com/watch?v=ErfnhcEV1O8", "https://www.youtube.com/watch?v=LJwtEaP2xKA", "https://www.youtube.com/watch?v=xmvxXXZUXdk", "https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-understanding-kl-divergence-2b382ca2b2a8"], "nodetype": "concept", "relative_importance": 1.212435565298214, "parent": "Probability_&_Statistics"}, "classes": "concept", "position": {"x": 3095.6233356871408, "y": 1733.15816562059}}, {"data": {"id": "59", "name": "Markov Chains", "lectures": "probability course 16-18", "description": "", "urls": ["https://www.khanacademy.org/computing/computer-science/informationtheory/moderninfotheory/v/markov_chains"], "nodetype": "concept", "relative_importance": 1.212435565298214, "parent": "Probability_&_Statistics"}, "classes": "concept", "position": {"x": 2046.7651126615128, "y": 2811.7618139960477}}, {"data": {"id": "60", "name": "Classification: Logistic regression & softmax", "lectures": "Machine Learning week 1-2", "description": "Classification is learning to categorise data into groups based on labels. In more mathematical vernacular, classification is the umbrella term for supervised learning problems with discrete output space.", "urls": ["https://www.youtube.com/watch?v=yIYKR4sgzI8", "https://christophm.github.io/interpretable-ml-book/logistic.html", "https://machinelearningmastery.com/logistic-regression-for-machine-learning/"], "nodetype": "concept", "relative_importance": 1, "parent": "Machine_Learning"}, "classes": "concept", "position": {"x": 3186.339426686613, "y": 1349.7600881271492}}, {"data": {"id": "61", "name": "Gradient Descent", "lectures": "", "description": "A large family of optimisation algorithms based on a simple observation: to reach the bottom of a valley, try walking downhill.", "urls": ["https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html", "https://ruder.io/optimizing-gradient-descent/"], "nodetype": "concept", "relative_importance": 1.4, "parent": "Optimization"}, "classes": "concept", "position": {"x": 4598.5414477679, "y": 1150.882834338651}}, {"data": {"id": "62", "name": "Regularization & Overfitting", "lectures": "Machine Learning week 1-2", "description": "Overfitting is a perennial problem in machine learning. If a model is only effective on the dataset it was trained on, and doesn't generalise to the wider world, it isn't useful. Regularization is umbrella term for methods used to mitigate overfitting.", "urls": ["https://www.datacamp.com/community/tutorials/towards-preventing-overfitting-regularization", "https://towardsdatascience.com/over-fitting-and-regularization-64d16100f45c", "https://towardsdatascience.com/machine-learning-regularization-and-over-fitting-simply-explained-d4dfdc256c9d"], "nodetype": "concept", "relative_importance": 1, "parent": "Machine_Learning"}, "classes": "concept", "position": {"x": 4225.142491724564, "y": 870.2117371110736}}, {"data": {"id": "63", "name": "Principal Component Analysis", "lectures": "Machine Learning week 7", "description": "", "urls": ["https://builtin.com/data-science/step-step-explanation-principal-component-analysis", "https://royalsocietypublishing.org/doi/10.1098/rsta.2015.0202"], "nodetype": "concept", "relative_importance": 1, "parent": "Machine_Learning"}, "classes": "concept", "position": {"x": 2768.3226063839215, "y": 1201.6430885295226}}, {"data": {"id": "64", "name": "Support Vector Machines", "lectures": "Machine Learning week 3", "description": "", "urls": ["https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47", "https://www.youtube.com/watch?v=efR1C6CvhmE", "http://web.mit.edu/6.034/wwwbob/svm-notes-long-08.pdf", "https://mml-book.github.io/book/mml-book.pdf#page=376"], "nodetype": "concept", "relative_importance": 1, "parent": "Machine_Learning"}, "classes": "concept", "position": {"x": 3202.0079580297506, "y": 901.9818393031826}}, {"data": {"id": "65", "name": "Perceptrons & Neural Networks", "lectures": "Machine Learning week 5-6", "description": "The basis of deep learning - that a network of connected neurons have the capacity to learn amazingly powerful and varied representations. This concept starts focused on the simplest case - one neuron - and builds up to many.", "urls": ["https://deepai.org/machine-learning-glossary-and-terms/perceptron#:~:text=A%20Perceptron%20is%20an%20algorithm", "a%20single%2Dlayer%20neural%20network.", "https://www.simplilearn.com/what-is-perceptron-tutorial", "https://www.youtube.com/watch?v=aiDv1NPdXvU", "https://www.youtube.com/watch?v=aircAruvnKk&vl=en", "https://www.youtube.com/watch?v=MfIjxPh6Pys&list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU&index=11", "http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/"], "nodetype": "concept", "relative_importance": 1.212435565298214, "parent": "Deep_Learning"}, "classes": "concept", "position": {"x": 3331.96884245093, "y": 624.7943831400106}}, {"data": {"id": "66", "name": "Activation Functions", "lectures": "", "description": "Biological neurons are typically modelled as firing when a threshold is reached. These provide similar non-linearities in artifical neurons. ", "urls": ["https://machinelearningmastery.com/choose-an-activation-function-for-deep-learning/", "https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6"], "nodetype": "concept", "relative_importance": 1, "parent": "Deep_Learning"}, "classes": "concept", "position": {"x": 3604.695775021498, "y": 477.386756279424}}, {"data": {"id": "67", "name": "Backpropagation", "lectures": "", "description": "The fundamental algorithm that enables training machine learning models with supervised learning, backpropagation updates model parameters to improve its predictions. ", "urls": ["http://neuralnetworksanddeeplearning.com/chap2.html", "https://www.youtube.com/watch?v=Ilg3gGewQ5U", "https://www.youtube.com/watch?v=tIeHLnjs5U8&vl=en", "https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/", "https://brilliant.org/wiki/backpropagation/", "https://www.youtube.com/watch?v=zUazLXZZA2U&list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU&index=12"], "nodetype": "concept", "relative_importance": 1.7146428199482244, "parent": "Deep_Learning"}, "classes": "concept", "position": {"x": 4006.2581355037664, "y": 304.78442468433366}}, {"data": {"id": "74", "name": "Ensemble Methods", "lectures": "Machine Learning week 4", "description": "Instead of relying on the inference of one trained neural network, train many (an ensemble), typically with different architectures, datasets or hyperparameters and average across them", "urls": ["https://www.toptal.com/machine-learning/ensemble-methods-machine-learning#:~:text=Ensemble%20methods%20are%20techniques%20that", "than%20a%20single%20model%20would.&text=These%20models%2C%20when%20used%20as", "are%20called%20%E2%80%9Dbase%20models%E2%80%9D.", "https://blog.statsbot.co/ensemble-learning-d1dcd548e936"], "nodetype": "concept", "relative_importance": 1, "parent": "Deep_Learning"}, "classes": "concept", "position": {"x": 3550.4382749797137, "y": -476.82977314975636}}, {"data": {"id": "75", "name": "Dropout", "lectures": "Machine Learning week 5-6", "description": "A method for regularizing neural networks that approximates training neural networks with many different architectures at once. Reduces the reliance on any individual node.", "urls": ["https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/", "https://jmlr.org/papers/v15/srivastava14a.html", "https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5", "https://www.coursera.org/lecture/convolutional-neural-networks/computer-vision-Ob1nR"], "nodetype": "concept", "relative_importance": 1, "parent": "Deep_Learning"}, "classes": "concept", "position": {"x": 4573.627426028807, "y": -483.2843373814959}}, {"data": {"id": "77", "name": "Convolutional Neural Networks", "lectures": "Machine Learning week 5-6", "description": "The fundamental technology underlying all current state-of-the-art approaches to all computer vision problems. Uses a set of learned filters to extract features from images at different scales.", "urls": ["https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53", "https://cs231n.github.io/convolutional-networks/", "https://www.freecodecamp.org/news/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050/"], "nodetype": "concept", "relative_importance": 1, "parent": "Deep_Learning"}, "classes": "concept", "position": {"x": 4272.263967140572, "y": 125.20421681697584}}, {"data": {"id": "78", "name": "K-means clustering", "lectures": "Machine Learning week 7", "description": "An unsupervised learning algorithm that learns to cluster data points into distinct groups based on their values.", "urls": ["https://towardsdatascience.com/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1", "https://www.youtube.com/watch?v=4b5d3muPQmA"], "nodetype": "concept", "relative_importance": 1, "parent": "Machine_Learning"}, "classes": "concept", "position": {"x": 3936.2822249224746, "y": 1491.4222995359735}}, {"data": {"id": "81", "name": "Expectation Maximization", "lectures": "Machine Learning week 8-10", "description": "", "urls": ["https://machinelearningmastery.com/expectation-maximization-em-algorithm/", "https://www.youtube.com/watch?v=REypj2sy_5U", "https://www.youtube.com/watch?v=rVfZHWTwXSA", "https://www.youtube.com/watch?v=rVfZHWTwXSA&list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU&index=14"], "nodetype": "concept", "relative_importance": 1, "parent": "Machine_Learning"}, "classes": "concept", "position": {"x": 3099.363719760625, "y": 1528.3753459283778}}, {"data": {"id": "82", "name": "EM Mixture of Gaussians", "lectures": "", "description": "", "urls": ["https://stephens999.github.io/fiveMinuteStats/intro_to_em.html", "https://www.ics.uci.edu/~smyth/courses/cs274/notes/EMnotes.pdf", "http://statweb.stanford.edu/~tibs/stat315a/LECTURES/em.pdf"], "nodetype": "concept", "relative_importance": 1, "parent": "Machine_Learning"}, "classes": "concept", "position": {"x": 2950.627987515527, "y": 1261.2591990530764}}, {"data": {"id": "83", "name": "Factor Analysis", "lectures": "Machine Learning week 8-10", "description": "", "urls": ["https://www.youtube.com/watch?v=WV_jcaDBZ2I", "https://stats.idre.ucla.edu/spss/seminars/introduction-to-factor-analysis/a-practical-introduction-to-factor-analysis/", "https://www.ibm.com/docs/SSLVMB_23.0.0/spss/base/idh_fact.html"], "nodetype": "concept", "relative_importance": 1, "parent": "Machine_Learning"}, "classes": "concept", "position": {"x": 2476.4251055729264, "y": 1138.1499037289539}}, {"data": {"id": "84", "name": "Probabilistic Graphical Models", "lectures": "Machine Learning week 8-10", "description": "A large family of probabilistic methods describing the relationships between random variables", "urls": ["https://towardsdatascience.com/introduction-to-probabilistic-graphical-models-b8e0bf459812", "https://ermongroup.github.io/cs228-notes/"], "nodetype": "concept", "relative_importance": 1.212435565298214, "parent": "Machine_Learning"}, "classes": "concept", "position": {"x": 3671.637642476766, "y": 1405.9468059436272}}, {"data": {"id": "85", "name": "Autoencoders", "lectures": "Machine Learning week 8-10 ", "description": "", "urls": ["https://www.jeremyjordan.me/autoencoders/", "https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798", "https://towardsdatascience.com/auto-encoder-what-is-it-and-what-is-it-used-for-part-1-3e5c6f017726", "https://www.deeplearningbook.org/contents/autoencoders.html"], "nodetype": "concept", "relative_importance": 1, "parent": "Deep_Learning"}, "classes": "concept", "position": {"x": 4301.821249502484, "y": -475.88209099460073}}, {"data": {"id": "86", "name": "Generative Adversarial Networks", "lectures": "Machine Learning week 8-10", "description": "", "urls": ["https://machinelearningmastery.com/what-are-generative-adversarial-networks-gans/", "https://developers.google.com/machine-learning/gan", "https://openai.com/blog/generative-models/", "https://arxiv.org/abs/1406.2661"], "nodetype": "concept", "relative_importance": 1, "parent": "Deep_Learning"}, "classes": "concept", "position": {"x": 4011.53649827584, "y": -507.88522955140894}}, {"data": {"id": "87", "name": "Recurrent Neural Networks", "lectures": "Machine Learning week 8-10", "description": "", "urls": ["https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks", "http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/", "http://karpathy.github.io/2015/05/21/rnn-effectiveness/"], "nodetype": "concept", "relative_importance": 1, "parent": "Deep_Learning"}, "classes": "concept", "position": {"x": 3325.725150538484, "y": 281.8930951687197}}, {"data": {"id": "88", "name": "LSTM", "lectures": "", "description": "Long Short-Term Memory (or LSTM for short) recurrent neural network neurons take inputs word-embeddings one-by-one.", "urls": ["https://colah.github.io/posts/2015-08-Understanding-LSTMs/", "https://machinelearningmastery.com/gentle-introduction-long-short-term-memory-networks-experts/", "https://www.youtube.com/watch?v=QciIcRxJvsM", "https://www.youtube.com/watch?v=LfnrRPFhkuY"], "nodetype": "concept", "relative_importance": 1, "parent": "Deep_Learning"}, "classes": "concept", "position": {"x": 3330.705763858178, "y": -11.67101255569341}}, {"data": {"id": "89", "name": "Gaussian Processes", "lectures": "not included in courses", "description": "", "urls": ["https://thegradient.pub/gaussian-process-not-quite-for-dummies/", "https://distill.pub/2019/visual-exploration-gaussian-processes", "https://towardsdatascience.com/an-intuitive-guide-to-gaussian-processes-ec2f0b45c71d"], "nodetype": "concept", "relative_importance": 1, "parent": "Machine_Learning"}, "classes": "concept", "position": {"x": 2267.2404781275363, "y": 936.4747341028808}}, {"data": {"id": "92", "name": "Symmetric Matrices", "lectures": "Linear Algebra course 25-34", "description": "A square matrix that is equal to it's transpose. In other words, it's symmetric around the main diagonal of the matrix", "urls": ["https://www.youtube.com/watch?v=UCc9q_cAhho", "https://people.math.carleton.ca/~kcheung/math/notes/MATH1107/wk10/10_symmetric_matrices.html", "https://people.revoledu.com/kardi/tutorial/LinearAlgebra/SymmetricMatrix.html"], "nodetype": "concept", "relative_importance": 1, "parent": "Linear_Algebra"}, "classes": "concept", "position": {"x": 791.011207820173, "y": 3257.8980879252767}}, {"data": {"id": "93", "name": "Positive Definite Matrices", "lectures": "", "description": "A key family of matrices with interesting properties and a wide array of use cases.", "urls": ["https://www.youtube.com/watch?v=UCc9q_cAhho", "https://www.math.utah.edu/~zwick/Classes/Fall2012_2270/Lectures/Lecture33_with_Examples.pdf", "https://www.youtube.com/watch?v=ojUQk_GNQbQ"], "nodetype": "concept", "relative_importance": 1, "parent": "Linear_Algebra"}, "classes": "concept", "position": {"x": 1644.7921167952622, "y": 3006.5891914177378}}, {"data": {"id": "94", "name": "Markov Matrices", "lectures": "Linear Algebra course 25-34", "description": "A Markov matrix is a square matrix with all nonnegative entries, and where the sum of the entries down any column is 1", "urls": ["https://www.math.utah.edu/~zwick/Classes/Fall2012_2270/Lectures/Lecture40_with_Examples.pdf", "https://www.youtube.com/watch?v=nnssRe5DewE"], "nodetype": "concept", "relative_importance": 1, "parent": "Linear_Algebra"}, "classes": "concept", "position": {"x": 1889.9801963619898, "y": 2622.268732255381}}, {"data": {"id": "98", "name": "Linear Discriminant Analysis", "lectures": "not included in courses", "description": "", "urls": ["https://sebastianraschka.com/Articles/2014_python_lda.html", "https://towardsdatascience.com/linear-discriminant-analysis-explained-f88be6c1e00b", "https://www.youtube.com/watch?v=azXCzI57Yfc"], "nodetype": "concept", "relative_importance": 1, "parent": "Machine_Learning"}, "classes": "concept", "position": {"x": 2662.2364892520654, "y": 891.8040572562566}}, {"data": {"id": "101", "name": "Markov Decision Processes", "lectures": "RL course, TN course?", "description": "The fundamental mathematical framework for RL and RL-like problems. A deep understanding of this concept is key to understanding RL.", "urls": ["https://www.youtube.com/watch?v=Jk2V9yA82YU", "https://www.youtube.com/watch?v=9g32v7bK3Co", "https://www.davidsilver.uk/wp-content/uploads/2020/03/MDP.pdf"], "nodetype": "concept", "relative_importance": 1.4, "parent": "Reinforcement_Learning"}, "classes": "concept", "position": {"x": 1856.007086124094, "y": 1506.9705689381572}}, {"data": {"id": "102", "name": "Model-based & Model-free RL", "lectures": "", "description": "A key differentiator that separates RL methods into two families. Model-based directly models how the environment evolves, so can simulate how an action now might affect the future states, while model-free methods do not, so can't simulate ahead.", "urls": ["https://www.youtube.com/watch?v=bFPoHrAoPoQ", "https://neptune.ai/blog/model-based-and-model-free-reinforcement-learning-pytennis-case-study", "https://www.youtube.com/watch?v=nnxHlg-2WgA", "https://www.youtube.com/watch?v=PnHCvfgC_ZA", "https://www.youtube.com/watch?v=_rKzhhDRq_4"], "nodetype": "concept", "relative_importance": 1, "parent": "Reinforcement_Learning"}, "classes": "concept", "position": {"x": 1534.1642049693505, "y": 1127.4026293028464}}, {"data": {"id": "103", "name": "Bellman Equations", "lectures": "", "description": "The foundational equations of RL. These define value functions based on policies and optimal behaviour in Markov Decision Processes.", "urls": ["https://www.youtube.com/watch?v=14BfO5lMiuk", "https://towardsdatascience.com/the-bellman-equation-59258a0d3fa7", "https://medium.com/analytics-vidhya/bellman-equation-and-dynamic-programming-773ce67fc6a7"], "nodetype": "concept", "relative_importance": 1.212435565298214, "parent": "Reinforcement_Learning"}, "classes": "concept", "position": {"x": 1846.20879402677, "y": 1119.253000878412}}, {"data": {"id": "104", "name": "Dynamic Programming: Policy & Value Iteration", "lectures": "", "description": "Solve MDPs exactly with these algorithms. A fundamental of RL, key aspects of these approaches are used in almost every RL algorithm.", "urls": ["http://web.mit.edu/15.053/www/AMP-Chapter-11.pdf", "https://www.educative.io/courses/grokking-dynamic-programming-patterns-for-coding-interviews/m2G1pAq0OO0"], "nodetype": "concept", "relative_importance": 1, "parent": "Reinforcement_Learning"}, "classes": "concept", "position": {"x": 1543.1772599863914, "y": 650.1686736440129}}, {"data": {"id": "105", "name": "Monte Carlo Learning", "lectures": "", "description": "RL methods that learn from rollouts of experience in the real environment.", "urls": ["https://www.davidsilver.uk/wp-content/uploads/2020/03/MC-TD.pdf", "https://medium.com/ai%C2%B3-theory-practice-business/reinforcement-learning-part-5-monte-carlo-and-temporal-difference-learning-889053aba07d", "https://towardsdatascience.com/monte-carlo-learning-b83f75233f92", "https://www.youtube.com/watch?v=uiPhlFrwcw8", "https://www.youtube.com/watch?v=mMEFFN1H5Cg"], "nodetype": "concept", "relative_importance": 1.4, "parent": "Reinforcement_Learning"}, "classes": "concept", "position": {"x": 1848.0591656023355, "y": 657.8867718530337}}, {"data": {"id": "106", "name": "Value Function Approximation", "lectures": "", "description": "Apply the Bellman Equations to approximate the value of a state. This is a key component of Q-learning, an algorithm which can achieve the optimal policy.", "urls": ["https://www.davidsilver.uk/wp-content/uploads/2020/03/FA.pdf", "https://web.stanford.edu/class/cs234/slides/lecture5.pdf", "https://www.youtube.com/watch?v=UoPei5o4fps", "https://www.youtube.com/watch?v=buptHUzDKcE", "https://www.youtube.com/watch?v=7Dg6KiI_0eM", "https://www.youtube.com/watch?v=Ijqkc7OLenI"], "nodetype": "concept", "relative_importance": 1.212435565298214, "parent": "Reinforcement_Learning"}, "classes": "concept", "position": {"x": 2043.2229587046854, "y": 396.2467194373755}}, {"data": {"id": "107", "name": "Actor-Critic", "lectures": "RL course, TN course?", "description": "A family of RL methods that explicitly train a policy and a value function. These tend to learn faster than both value-based RL methods or policy-based methods.", "urls": ["https://www.davidsilver.uk/wp-content/uploads/2020/03/pg.pdf#page=23", "https://www.youtube.com/watch?v=LawaN3BdI00", "https://www.youtube.com/watch?v=bRfUxQs6xIM", "https://www.youtube.com/watch?v=n6K8FfqQ7ds", "https://towardsdatascience.com/understanding-actor-critic-methods-931b97b6df3f", "http://incompleteideas.net/book/first/ebook/node66.html"], "nodetype": "concept", "relative_importance": 1, "parent": "Reinforcement_Learning"}, "classes": "concept", "position": {"x": 1749.2313140572971, "y": 115.83580904807451}}, {"data": {"id": "108", "name": "Q-learning", "lectures": "", "description": "As the first RL approach to achieve superhuman play on Atari games, Q-learning has cemented its place as a key RL algorithm.", "urls": ["https://www.davidsilver.uk/wp-content/uploads/2020/03/control.pdf", "https://towardsdatascience.com/a-beginners-guide-to-q-learning-c3e2a30a653c", "https://www.gatsby.ucl.ac.uk/~dayan/papers/cjch.pdf", "https://www.freecodecamp.org/news/an-introduction-to-q-learning-reinforcement-learning-14ac0b4493cc/"], "nodetype": "concept", "relative_importance": 1, "parent": "Reinforcement_Learning"}, "classes": "concept", "position": {"x": 2041.968231519087, "y": 129.41890517270298}}, {"data": {"id": "109", "name": "Exploration & Exploitation", "lectures": "", "description": "A classic dichotomy for RL - should I explore (and learn more about the environment) or exploit (and do what I already know works to achieve higher rewards)? How should I balance these two?", "urls": ["https://www.davidsilver.uk/wp-content/uploads/2020/03/XX.pdf", "https://towardsdatascience.com/intro-to-reinforcement-learning-the-explore-exploit-dilemma-463ceb004989", "https://www.manifold.ai/exploration-vs-exploitation-in-reinforcement-learning", "https://www.youtube.com/watch?v=eM6IBYVqXEA", "https://www.youtube.com/watch?v=sGuiWX07sKw"], "nodetype": "concept", "relative_importance": 1, "parent": "Reinforcement_Learning"}, "classes": "concept", "position": {"x": 2061.230298945892, "y": 1113.3879576399836}}, {"data": {"id": "111", "name": "Markov Random Fields", "lectures": "", "description": "Markov Random Fields (MRFs) have applications in computer vision, graphics and computational biology. They're the undirected counterpart to the directed Bayesian Networks.", "urls": ["https://ermongroup.github.io/cs228-notes/representation/undirected/", "https://www.fmrib.ox.ac.uk/datasets/techrep/tr00yz1/tr00yz1/node4.html", "https://www.youtube.com/watch?v=iBQkZdPHlCs", ""], "nodetype": "concept", "relative_importance": 1, "parent": "Machine_Learning"}, "classes": "concept", "position": {"x": 3578.243652854649, "y": 1185.6781114697544}}, {"data": {"id": "112", "name": "Bayesian Networks", "lectures": "", "description": "With uses ranging from prediction, anomaly detection to reasoning and decision making under uncertainty, Bayesian Networks are a highly flexible form of probabilistic graphical model. Bayesian networks are directed graphical models, showing how random variables depend on one another.", "urls": ["https://ermongroup.github.io/cs228-notes/representation/directed/", "https://www.youtube.com/watch?v=tMwfGGkj8DE", "https://www.youtube.com/watch?v=TuGDMj43ehw", "https://www.cs.ubc.ca/~murphyk/Bayes/bnintro.html"], "nodetype": "concept", "relative_importance": 1.212435565298214, "parent": "Machine_Learning"}, "classes": "concept", "position": {"x": 3817.3345472746173, "y": 995.6275057985893}}, {"data": {"id": "113", "name": "Variable Elimination", "lectures": "", "description": "The most basic exact inference algorithm for probabilistic graphical models.", "urls": ["https://ermongroup.github.io/cs228-notes/inference/ve/", "https://www.cs.ubc.ca/~kevinlb/teaching/cs322%20-%202006-7/Lectures/lect29.pdf", "https://www.cs.cmu.edu/~epxing/Class/10708-14/scribe_notes/scribe_note_lecture4.pdf", "https://www.cs.upc.edu/~larrosa/MEI-CSI-files/BN/2-BN-VE.pdf"], "nodetype": "concept", "relative_importance": 1, "parent": "Machine_Learning"}, "classes": "concept", "position": {"x": 3737.479234020747, "y": 776.4393172844669}}, {"data": {"id": "114", "name": "Belief Propagation", "lectures": "", "description": "An algorithm for inference in graphical models using message-passing", "urls": ["https://ermongroup.github.io/cs228-notes/inference/jt/", "https://www.ski.org/sites/default/files/publications/bptutorial.pdf", "http://helper.ipam.ucla.edu/publications/gss2013/gss2013_11344.pdf"], "nodetype": "concept", "relative_importance": 1, "parent": "Machine_Learning"}, "classes": "concept", "position": {"x": 3955.717065396615, "y": 786.3566411119283}}, {"data": {"id": "117", "name": "Multivariate Gaussians", "lectures": "", "description": "", "urls": ["http://cs229.stanford.edu/section/gaussians.pdf", "https://www.cs.cmu.edu/~epxing/Class/10701-08s/recitation/gaussian.pdf", "https://www.youtube.com/watch?v=JjB58InuTqM", "https://www.youtube.com/watch?v=eho8xH3E6mE"], "nodetype": "concept", "relative_importance": 1.5652475842498528, "parent": "Probability_&_Statistics"}, "classes": "concept", "position": {"x": 2510.3143711607095, "y": 1843.1695529757421}}, {"data": {"id": "118", "name": "Learning in Sequence Models", "lectures": "", "description": "", "urls": ["https://wiki.pathmind.com/lstm#backpropagation", "https://towardsdatascience.com/sequence-models-by-andrew-ng-11-lessons-learned-c62fb1d3485b", "https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html", "https://www.youtube.com/watch?v=_i3aqgKVNQI&list=PLkDaE6sCZn6F6wUI9tvS_Gw1vaFAx6rd6", "https://www.youtube.com/watch?v=CznICCPa63Q", "https://www.youtube.com/watch?v=oF0Rboc4IJw"], "nodetype": "concept", "relative_importance": 1, "parent": "Deep_Learning"}, "classes": "concept", "position": {"x": 3331.088102182191, "y": -484.8285870769239}}, {"data": {"id": "119", "name": "Policy Gradient Methods", "lectures": "", "description": "A family of model-free RL methods based on the policy gradient theorem. It's most notable members include PPO, TRPO and REINFORCE.", "urls": ["https://www.davidsilver.uk/wp-content/uploads/2020/03/pg.pdf", "http://www.scholarpedia.org/article/Policy_gradient_methods", "https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html", "https://towardsdatascience.com/policy-gradient-methods-104c783251e0", "https://www.youtube.com/watch?v=A_2U6Sx67sE", "https://www.youtube.com/watch?v=KHZVXao4qXs"], "nodetype": "concept", "relative_importance": 1, "parent": "Reinforcement_Learning"}, "classes": "concept", "position": {"x": 1639.6264891194605, "y": 388.6675377598405}}, {"data": {"id": "123", "name": "Estimators", "lectures": "", "description": "", "urls": ["https://www.youtube.com/watch?v=qvR7sSGphQ4&ab_channel=BenLambert", "https://www.youtube.com/watch?v=UxbY85Cm9SQ&ab_channel=BenLambertBenLambert", "https://warwick.ac.uk/fac/soc/economics/staff/vetroeger/teaching/qrmnew2.pdf", "https://www.statisticshowto.com/estimator/"], "nodetype": "concept", "relative_importance": 1.212435565298214, "parent": "Probability_&_Statistics"}, "classes": "concept", "position": {"x": 3748.873204810099, "y": 2296.4401653153536}}, {"data": {"id": "124", "name": "TD & TD(lambda) learning", "lectures": "", "description": "Temporal Difference (or TD) learning refers to RL methods that learn online while interacting with an environment", "urls": ["https://deepmind.com/blog/article/Dopamine-and-temporal-difference-learning-A-fruitful-relationship-between-neuroscience-and-AI", "https://medium.com/@violante.andre/simple-reinforcement-learning-temporal-difference-learning-e883ea0d65b0", "https://web.stanford.edu/group/pdplab/pdphandbook/handbookch10.html", "https://www.youtube.com/watch?v=L64E_NTZJ_0", "https://www.youtube.com/watch?v=LyCpuLikLyQ", "https://www.youtube.com/watch?v=PnHCvfgC_ZA", ""], "nodetype": "concept", "relative_importance": 1, "parent": "Reinforcement_Learning"}, "classes": "concept", "position": {"x": 1842.4226035110112, "y": 396.0870570383048}}, {"data": {"id": "128", "name": "Cross Entropy", "lectures": "", "description": "", "urls": ["https://machinelearningmastery.com/cross-entropy-for-machine-learning/", "https://towardsdatascience.com/cross-entropy-loss-function-f38c4ec8643e", "http://neuralnetworksanddeeplearning.com/chap3.html", "https://stackoverflow.com/questions/41990250/what-is-cross-entropy/41990932", "https://www.youtube.com/watch?v=6ArSys5qHAU"], "nodetype": "concept", "relative_importance": 1, "parent": "Probability_&_Statistics"}, "classes": "concept", "position": {"x": 3076.7518750989957, "y": 1979.1243323515578}}, {"data": {"id": "129", "name": "Multivariate PDFs & PMFs", "lectures": "", "description": "", "urls": ["https://www.dam.brown.edu/people/huiwang/classes/am165/Prob_ch5_2007.pdf", "https://pages.ucsd.edu/~rlevy/pmsl_textbook/chapters/pmsl_3.pdf", "https://www.stat.uchicago.edu/~stigler/Stat244/ch3withfigs.pdf", "http://cs229.stanford.edu/notes2020fall/notes2020fall/cs229-prob.pdf#page=6"], "nodetype": "concept", "relative_importance": 1.212435565298214, "parent": "Probability_&_Statistics"}, "classes": "concept", "position": {"x": 2822.1599768773513, "y": 3116.4752285817267}}, {"data": {"id": "130", "name": "Stochastic Gradient Descent", "lectures": "", "description": "The key algorithm used to train the majority of deep learning methods. If it's deep and it learns, chances are it's using SGD!", "urls": ["https://www.youtube.com/watch?v=k3AiUhwHQ28", "https://ruder.io/optimizing-gradient-descent/", "https://towardsdatascience.com/stochastic-gradient-descent-clearly-explained-53d239905d31", "https://www.youtube.com/watch?v=vMh0zPT0tLI"], "nodetype": "concept", "relative_importance": 1.4, "parent": "Optimization"}, "classes": "concept", "position": {"x": 4591.832409709833, "y": 810.8390019744493}}, {"data": {"id": "131", "name": "Lagrangian Multipliers", "lectures": "", "description": "", "urls": ["https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/lagrange-multipliers-and-constrained-optimization/v/constrained-optimization-introduction", "https://tutorial.math.lamar.edu/classes/calciii/lagrangemultipliers.aspx"], "nodetype": "concept", "relative_importance": 1, "parent": "Optimization"}, "classes": "concept", "position": {"x": 4416.373781236017, "y": 1448.4228005986836}}, {"data": {"id": "132", "name": "Partial derivatives", "lectures": "", "description": "", "urls": ["https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/partial-derivatives/v/partial-derivatives-introduction", "https://mml-book.github.io/book/mml-book.pdf#page=152", "https://www.youtube.com/watch?v=JAf_aSIJryg", "https://www.mathsisfun.com/calculus/derivatives-partial.html"], "nodetype": "concept", "relative_importance": 1, "parent": "Calculus"}, "classes": "concept", "position": {"x": 4304.329294792409, "y": 2372.352004961863}}, {"data": {"id": "133", "name": "Product Rule of Probability", "lectures": "", "description": "", "urls": ["https://mml-book.github.io/book/mml-book.pdf#page=190", "https://brilliant.org/wiki/probability-rule-of-product/", "https://www.youtube.com/watch?v=1O2EBfQ-MgU"], "nodetype": "concept", "relative_importance": 1, "parent": "Probability_&_Statistics"}, "classes": "concept", "position": {"x": 3278.3282455025646, "y": 2402.6886642046356}}], "edges": [{"data": {"id": "1_2", "source": "1", "target": "2"}}, {"data": {"id": "28_3", "source": "28", "target": "3"}}, {"data": {"id": "2_3", "source": "2", "target": "3"}}, {"data": {"id": "3_4", "source": "3", "target": "4"}}, {"data": {"id": "6_5", "source": "6", "target": "5"}}, {"data": {"id": "3_5", "source": "3", "target": "5"}}, {"data": {"id": "2_6", "source": "2", "target": "6"}}, {"data": {"id": "27_7", "source": "27", "target": "7"}}, {"data": {"id": "9_10", "source": "9", "target": "10"}}, {"data": {"id": "20_10", "source": "20", "target": "10"}}, {"data": {"id": "10_11", "source": "10", "target": "11"}}, {"data": {"id": "11_12", "source": "11", "target": "12"}}, {"data": {"id": "11_13", "source": "11", "target": "13"}}, {"data": {"id": "129_14", "source": "129", "target": "14"}}, {"data": {"id": "11_15", "source": "11", "target": "15"}}, {"data": {"id": "133_16", "source": "133", "target": "16"}}, {"data": {"id": "17_18", "source": "17", "target": "18"}}, {"data": {"id": "18_19", "source": "18", "target": "19"}}, {"data": {"id": "17_20", "source": "17", "target": "20"}}, {"data": {"id": "23_22", "source": "23", "target": "22"}}, {"data": {"id": "17_23", "source": "17", "target": "23"}}, {"data": {"id": "5_24", "source": "5", "target": "24"}}, {"data": {"id": "4_25", "source": "4", "target": "25"}}, {"data": {"id": "15_26", "source": "15", "target": "26"}}, {"data": {"id": "5_27", "source": "5", "target": "27"}}, {"data": {"id": "1_28", "source": "1", "target": "28"}}, {"data": {"id": "28_29", "source": "28", "target": "29"}}, {"data": {"id": "4_30", "source": "4", "target": "30"}}, {"data": {"id": "42_30", "source": "42", "target": "30"}}, {"data": {"id": "5_31", "source": "5", "target": "31"}}, {"data": {"id": "11_32", "source": "11", "target": "32"}}, {"data": {"id": "20_33", "source": "20", "target": "33"}}, {"data": {"id": "35_34", "source": "35", "target": "34"}}, {"data": {"id": "15_35", "source": "15", "target": "35"}}, {"data": {"id": "15_36", "source": "15", "target": "36"}}, {"data": {"id": "129_36", "source": "129", "target": "36"}}, {"data": {"id": "30_41", "source": "30", "target": "41"}}, {"data": {"id": "31_41", "source": "31", "target": "41"}}, {"data": {"id": "24_42", "source": "24", "target": "42"}}, {"data": {"id": "16_45", "source": "16", "target": "45"}}, {"data": {"id": "123_45", "source": "123", "target": "45"}}, {"data": {"id": "123_46", "source": "123", "target": "46"}}, {"data": {"id": "16_56", "source": "16", "target": "56"}}, {"data": {"id": "11_57", "source": "11", "target": "57"}}, {"data": {"id": "128_58", "source": "128", "target": "58"}}, {"data": {"id": "11_59", "source": "11", "target": "59"}}, {"data": {"id": "56_60", "source": "56", "target": "60"}}, {"data": {"id": "19_61", "source": "19", "target": "61"}}, {"data": {"id": "22_61", "source": "22", "target": "61"}}, {"data": {"id": "61_62", "source": "61", "target": "62"}}, {"data": {"id": "117_63", "source": "117", "target": "63"}}, {"data": {"id": "60_64", "source": "60", "target": "64"}}, {"data": {"id": "131_64", "source": "131", "target": "64"}}, {"data": {"id": "42_64", "source": "42", "target": "64"}}, {"data": {"id": "27_64", "source": "27", "target": "64"}}, {"data": {"id": "2_65", "source": "2", "target": "65"}}, {"data": {"id": "65_66", "source": "65", "target": "66"}}, {"data": {"id": "61_67", "source": "61", "target": "67"}}, {"data": {"id": "66_67", "source": "66", "target": "67"}}, {"data": {"id": "67_74", "source": "67", "target": "74"}}, {"data": {"id": "62_75", "source": "62", "target": "75"}}, {"data": {"id": "67_75", "source": "67", "target": "75"}}, {"data": {"id": "130_75", "source": "130", "target": "75"}}, {"data": {"id": "33_77", "source": "33", "target": "77"}}, {"data": {"id": "67_77", "source": "67", "target": "77"}}, {"data": {"id": "130_77", "source": "130", "target": "77"}}, {"data": {"id": "23_78", "source": "23", "target": "78"}}, {"data": {"id": "58_81", "source": "58", "target": "81"}}, {"data": {"id": "117_82", "source": "117", "target": "82"}}, {"data": {"id": "81_82", "source": "81", "target": "82"}}, {"data": {"id": "117_83", "source": "117", "target": "83"}}, {"data": {"id": "56_84", "source": "56", "target": "84"}}, {"data": {"id": "45_84", "source": "45", "target": "84"}}, {"data": {"id": "46_84", "source": "46", "target": "84"}}, {"data": {"id": "130_85", "source": "130", "target": "85"}}, {"data": {"id": "67_85", "source": "67", "target": "85"}}, {"data": {"id": "58_85", "source": "58", "target": "85"}}, {"data": {"id": "77_86", "source": "77", "target": "86"}}, {"data": {"id": "56_86", "source": "56", "target": "86"}}, {"data": {"id": "65_87", "source": "65", "target": "87"}}, {"data": {"id": "87_88", "source": "87", "target": "88"}}, {"data": {"id": "117_89", "source": "117", "target": "89"}}, {"data": {"id": "1_92", "source": "1", "target": "92"}}, {"data": {"id": "1_93", "source": "1", "target": "93"}}, {"data": {"id": "2_94", "source": "2", "target": "94"}}, {"data": {"id": "59_94", "source": "59", "target": "94"}}, {"data": {"id": "93_94", "source": "93", "target": "94"}}, {"data": {"id": "63_98", "source": "63", "target": "98"}}, {"data": {"id": "83_98", "source": "83", "target": "98"}}, {"data": {"id": "59_101", "source": "59", "target": "101"}}, {"data": {"id": "101_102", "source": "101", "target": "102"}}, {"data": {"id": "101_103", "source": "101", "target": "103"}}, {"data": {"id": "102_104", "source": "102", "target": "104"}}, {"data": {"id": "103_104", "source": "103", "target": "104"}}, {"data": {"id": "103_105", "source": "103", "target": "105"}}, {"data": {"id": "105_106", "source": "105", "target": "106"}}, {"data": {"id": "106_107", "source": "106", "target": "107"}}, {"data": {"id": "119_107", "source": "119", "target": "107"}}, {"data": {"id": "106_108", "source": "106", "target": "108"}}, {"data": {"id": "101_109", "source": "101", "target": "109"}}, {"data": {"id": "84_111", "source": "84", "target": "111"}}, {"data": {"id": "84_112", "source": "84", "target": "112"}}, {"data": {"id": "112_113", "source": "112", "target": "113"}}, {"data": {"id": "112_114", "source": "112", "target": "114"}}, {"data": {"id": "3_117", "source": "3", "target": "117"}}, {"data": {"id": "35_117", "source": "35", "target": "117"}}, {"data": {"id": "36_117", "source": "36", "target": "117"}}, {"data": {"id": "67_118", "source": "67", "target": "118"}}, {"data": {"id": "88_118", "source": "88", "target": "118"}}, {"data": {"id": "105_119", "source": "105", "target": "119"}}, {"data": {"id": "13_123", "source": "13", "target": "123"}}, {"data": {"id": "15_123", "source": "15", "target": "123"}}, {"data": {"id": "105_124", "source": "105", "target": "124"}}, {"data": {"id": "57_128", "source": "57", "target": "128"}}, {"data": {"id": "11_129", "source": "11", "target": "129"}}, {"data": {"id": "61_130", "source": "61", "target": "130"}}, {"data": {"id": "23_131", "source": "23", "target": "131"}}, {"data": {"id": "132_131", "source": "132", "target": "131"}}, {"data": {"id": "17_132", "source": "17", "target": "132"}}, {"data": {"id": "14_133", "source": "14", "target": "133"}}]}
